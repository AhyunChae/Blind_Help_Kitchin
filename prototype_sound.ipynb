{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ad0a68-9f68-41e9-a821-ee2c54592ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561548ef-35bd-44d8-bba5-abe1435f4ca4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 전처리 및 후처리 추가\n",
    "import cv2, torch, pandas, numpy as np, threading, queue, ncnn, sounddevice as sd, scipy.io.wavfile\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "IMG_SIZE = 320\n",
    "CONF_TH = 0.7\n",
    "FRAME_SKIP = 2\n",
    "IOU_TH = 0.25\n",
    "\n",
    "WARNING_TXT_ORG = (30,30)\n",
    "DERECTION_ORG = (430,450)\n",
    "\n",
    "COLOR_RED = (0,0,255)\n",
    "COLOR_GREEN = (0,255,0)\n",
    "COLOR_BLUE = (255,0,0)\n",
    "\n",
    "handle_pixel = []\n",
    "blade_pixel = []\n",
    "\n",
    "class Sound(threading.Thread):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def run(self):\n",
    "        winsound.Beep(frequency=500, duration=100)\n",
    "\n",
    "# 그리기\n",
    "def draw_landmarks_on_image(tools_dect, hand_dect, frame):\n",
    "    landmarks_list = hand_dect.hand_landmarks\n",
    "    annotated_image = np.copy(frame)\n",
    "\n",
    "    # 도구 박스 그리기\n",
    "    for (x1,y1,x2,y2), s, _ in tools_dect:\n",
    "        cv2.rectangle(annotated_image, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "\n",
    "    # 손 랜드마크 그리기\n",
    "    for landmark in landmarks_list:\n",
    "        landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        for lm in landmark: \n",
    "            landmarks_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z)])\n",
    "            \n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            landmarks_proto,\n",
    "            solutions.hands.HAND_CONNECTIONS,\n",
    "            solutions.drawing_styles.get_default_hand_landmarks_style()\n",
    "        )\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "# 겹칩 확인\n",
    "def detection_box(tools_dect, hand_dect, frame):\n",
    "    # boolean 마스킹\n",
    "    # 날과 손잡이인 경우만 가져옴\n",
    "    blade_xy = [ tools[0] for tools in tools_dect if tools[2] == 0 ]\n",
    "    handle_xy = [ tools[0] for tools in tools_dect if tools[2] == 1 ]\n",
    "\n",
    "    # 이전 프레임 좌표 저장\n",
    "    global handle_pixel, blade_pixel\n",
    "    if len(handle_xy) > 0:\n",
    "        handle_pixel = save_pixel(handle_xy)\n",
    "        \n",
    "    if len(blade_xy) > 0:\n",
    "        blade_pixel = save_pixel(blade_xy)\n",
    "\n",
    "    # 손이 겹쳤는지 확인\n",
    "    annotated_image = np.copy(frame)\n",
    "    hand_list = hand_dect.hand_landmarks\n",
    "    H, W, _ = annotated_image.shape\n",
    "    \n",
    "    flag_blade = False\n",
    "    flag_handle = False\n",
    "    for hand in hand_list:\n",
    "        middle_x = (int(hand[0].x*W) + int(hand[9].x*W)) // 2\n",
    "        middle_y = (int(hand[0].y*H) + int(hand[9].y*H)) // 2\n",
    "        cv2.circle(annotated_image, (middle_x, middle_y), 5, COLOR_BLUE, -1, cv2.LINE_AA)\n",
    "        \n",
    "        # 손잡이 확인\n",
    "        for handle in handle_pixel:\n",
    "            handle_middle_x = (handle[0] + handle[2]) // 2\n",
    "            handle_middle_y = (handle[1] + handle[3]) // 2\n",
    "            cv2.circle(annotated_image, (handle_middle_x, handle_middle_y), 5, (255,255,0), -1, cv2.LINE_AA)\n",
    "\n",
    "            if check_inside(handle, middle_x, middle_y):\n",
    "                flag_handle = True\n",
    "                break\n",
    "                \n",
    "            if middle_x < handle_middle_x:\n",
    "                if middle_y < handle_middle_y:\n",
    "                    draw_text(annotated_image, \"Right-Up\", DERECTION_ORG, COLOR_BLUE)\n",
    "                else:\n",
    "                    draw_text(annotated_image, \"Right-Down\", DERECTION_ORG, COLOR_BLUE)\n",
    "                    \n",
    "            elif middle_x > handle_middle_x:\n",
    "                if middle_y < handle_middle_y:\n",
    "                    draw_text(annotated_image, \"Left-Up\", DERECTION_ORG, COLOR_BLUE)\n",
    "                else:\n",
    "                    draw_text(annotated_image, \"Left-Down\", DERECTION_ORG, COLOR_BLUE)\n",
    "            \n",
    "        \n",
    "        for lm in hand:\n",
    "            lm_x = int(lm.x * W)\n",
    "            lm_y = int(lm.y * H)\n",
    "            \n",
    "            # 날 확인\n",
    "            for blade in blade_pixel:\n",
    "                if check_inside(blade, lm_x, lm_y):\n",
    "                    flag_blade = True\n",
    "                    break\n",
    "                            \n",
    "    if flag_blade:\n",
    "        if flag_handle:\n",
    "            draw_text(annotated_image, \"DETECTED\", WARNING_TXT_ORG, COLOR_GREEN)\n",
    "        else:\n",
    "            sd.play(danger_data, danger_samplerate)\n",
    "            draw_text(annotated_image, \"DANGER\", WARNING_TXT_ORG, COLOR_RED)\n",
    "    elif flag_handle:\n",
    "        draw_text(annotated_image, \"DETECTED\", WARNING_TXT_ORG, COLOR_GREEN)\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "def save_pixel(boxes):\n",
    "    lr = []\n",
    "    for x1,y1,x2,y2 in boxes:\n",
    "        lr.append([x1,y1,x2,y2])\n",
    "    return lr\n",
    "\n",
    "def check_inside(box, x, y):\n",
    "    if box[0] <= x <= box[2] and box[1] <= y <= box[3]: \n",
    "        return True\n",
    "    else: return False\n",
    "\n",
    "def draw_text(image, text, org, color):\n",
    "    cv2.putText(image, text, org, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3, cv2.LINE_AA)\n",
    "\n",
    "def warnning_sound(sound_queue):\n",
    "    def danger_play(state):\n",
    "        if state == \"stop\": return\n",
    "        elif state == \"danger\":\n",
    "            sd.play(danger_data, danger_samplerate)\n",
    "            danger_play(state)\n",
    "        \n",
    "    while True:\n",
    "        try:\n",
    "            state = sound_queue.get(timeout=0.1)\n",
    "            if state == \"quit\": break\n",
    "            danger_play(state)\n",
    "                \n",
    "        except queue.Empty:\n",
    "            continue\n",
    "            \n",
    "    \n",
    "\n",
    "# 전처리\n",
    "def letterbox(img, new=IMG_SIZE, color=(114,114,114)):\n",
    "    h, w = img.shape[:2]\n",
    "    r = min(new / h, new / w)\n",
    "    nh, nw = int(round(h * r)), int(round(w * r))\n",
    "    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    canvas = np.full((new, new, 3), color, dtype=np.uint8)\n",
    "    top = (new - nh) // 2\n",
    "    left = (new - nw) // 2\n",
    "    canvas[top:top+nh, left:left+nw] = resized\n",
    "    return canvas, r, left, top\n",
    "\n",
    "def nms(dets, iou_th=IOU_TH):\n",
    "    # dets: [([x1,y1,x2,y2], score, cls_id), ...] in letterbox 좌표\n",
    "    if not dets: return []\n",
    "    boxes = np.array([d[0] for d in dets], dtype=np.float32)\n",
    "    scores = np.array([d[1] for d in dets], dtype=np.float32)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if order.size == 1: break\n",
    "        rest = order[1:]\n",
    "        xx1 = np.maximum(boxes[i,0], boxes[rest,0])\n",
    "        yy1 = np.maximum(boxes[i,1], boxes[rest,1])\n",
    "        xx2 = np.minimum(boxes[i,2], boxes[rest,2])\n",
    "        yy2 = np.minimum(boxes[i,3], boxes[rest,3])\n",
    "        inter = np.maximum(0.0, xx2 - xx1) * np.maximum(0.0, yy2 - yy1)\n",
    "        area_i = (boxes[i,2] - boxes[i,0]) * (boxes[i,3] - boxes[i,1])\n",
    "        area_r = (boxes[rest,2] - boxes[rest,0]) * (boxes[rest,3] - boxes[rest,1])\n",
    "        iou = inter / (area_i + area_r - inter + 1e-6)\n",
    "        order = rest[iou <= iou_th]\n",
    "    return [dets[k] for k in keep]\n",
    "\n",
    "def tools_inference(frame):\n",
    "    H, W, _ = frame.shape\n",
    "    img_lbx, r, lpad, tpad = letterbox(frame, IMG_SIZE)\n",
    "    img_rgb = cv2.cvtColor(img_lbx, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    input_mat = ncnn.Mat.from_pixels(img_rgb, ncnn.Mat.PixelType.PIXEL_RGB, IMG_SIZE, IMG_SIZE)\n",
    "    input_mat.substract_mean_normalize([0,0,0], [1/255.0, 1/255.0, 1/255.0])\n",
    "\n",
    "    # 추론 시작\n",
    "    ex = net.create_extractor()\n",
    "    ex.input(\"in0\", input_mat)\n",
    "    _, result = ex.extract(\"out0\")\n",
    "\n",
    "    arr = result.numpy()\n",
    "    D, N = arr.shape\n",
    "    A = arr.T  # (N, D) : 한 행이 한 후보\n",
    "    cx, cy, w, h = A[:, 0], A[:, 1], A[:, 2], A[:, 3]\n",
    "\n",
    "    cls_scores = A[:, 4:7]              # (N,3)\n",
    "    cls_ids = np.argmax(cls_scores, axis=1)\n",
    "    scores  = cls_scores[np.arange(N), cls_ids]\n",
    "    \n",
    "    # 인식률로 가져오기\n",
    "    keep = scores >= CONF_TH\n",
    "    if not np.any(keep): return []\n",
    "    cx = cx[keep]; cy = cy[keep]; w = w[keep]; h = h[keep]\n",
    "    scores = scores[keep]; cls_ids = cls_ids[keep]\n",
    "\n",
    "    # cxcywh -> xyxy (레터박스된 IMG_SIZE 기준)\n",
    "    x1 = cx - w/2; y1 = cy - h/2\n",
    "    x2 = cx + w/2; y2 = cy + h/2\n",
    "\n",
    "    # 원본 좌표로 역변환\n",
    "    x1 = (x1 - lpad) / r; y1 = (y1 - tpad) / r\n",
    "    x2 = (x2 - lpad) / r; y2 = (y2 - tpad) / r\n",
    "\n",
    "    # 클리핑\n",
    "    x1 = np.clip(x1, 0, W); y1 = np.clip(y1, 0, H)\n",
    "    x2 = np.clip(x2, 0, W); y2 = np.clip(y2, 0, H)\n",
    "\n",
    "    dets = [(\n",
    "        [int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])], \n",
    "        float(scores[i]), int(cls_ids[i])\n",
    "        ) \n",
    "        for i in range(len(scores))\n",
    "    ]\n",
    "    dets = nms(dets, IOU_TH)\n",
    "    \n",
    "    return dets\n",
    "\n",
    "\n",
    "# ===================================================\n",
    "# 손 랜드마크 모델 가져오기\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "hand_detector = vision.HandLandmarker.create_from_options(options)\n",
    "# ===================================================\n",
    "# 칼 구분 모델 가져오기 (ncnn 네트)\n",
    "net = ncnn.Net()\n",
    "net.opt.num_threads = 4\n",
    "net.opt.use_fp16_storage = True\n",
    "net.opt.use_fp16_arithmetic = True\n",
    "\n",
    "net.load_param(\"knife_total_320.ncnn.param\")\n",
    "net.load_model(\"knife_total_320.ncnn.bin\")\n",
    "# ===================================================\n",
    "\n",
    "warnning_queue = queue.Queue()\n",
    "lock = threading.Lock()\n",
    "warnning_thread = threading.Thread(target=warnning_sound, args=(warnning_queue,))\n",
    "warnning_thread.daemon = True\n",
    "warnning_thread.start()\n",
    "\n",
    "# 캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹 캠을 열 수 없습니다\")\n",
    "    exit()\n",
    "\n",
    "fid = 0\n",
    "danger_samplerate, danger_data = scipy.io.wavfile.read('danger.wav')\n",
    "\n",
    "# 실행부\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret: break\n",
    "    \n",
    "    frame_bgr = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_bgr)\n",
    "\n",
    "    # 프레임 스킵\n",
    "    fid += 1\n",
    "    if fid % (FRAME_SKIP + 1) == 1:\n",
    "        tools_result = tools_inference(frame)\n",
    "        hand_result = hand_detector.detect(mp_image)\n",
    "\n",
    "    # 결과 그리기\n",
    "    sound_state = \"stay\"\n",
    "    drawing_image = draw_landmarks_on_image(tools_result, hand_result, frame)\n",
    "    annotated_image = detection_box(tools_result, hand_result, drawing_image)\n",
    "\n",
    "    cv2.imshow(\"hand_land\", annotated_image)\n",
    "    \n",
    "    # q키를 누르면 종료\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "    \n",
    "# 종료 시 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
