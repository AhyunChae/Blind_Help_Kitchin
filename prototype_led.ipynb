{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2a714a-b7c9-4bfd-b948-284249c77c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ?꾩쿂由?諛??꾩쿂由?異붽?\n",
    "import cv2\n",
    "import torch\n",
    "import pandas\n",
    "import numpy as np\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "import ncnn\n",
    "import RPi.GPIO as GPIO\n",
    "\n",
    "IMG_SIZE = 320 # resize size\n",
    "CONF_TH = 0.6\n",
    "FRAME_SKIP = 2\n",
    "IOU_TH = 0.25\n",
    "DETECT_PADDING = 30\n",
    "\n",
    "COLOR_RED = (0,0,255)\n",
    "COLOR_GREEN = (0,255,0)\n",
    "COLOR_BLUE = (255,0,0)\n",
    "\n",
    "handle_pixel = []\n",
    "blade_pixel = []\n",
    "\n",
    "# 洹몃━湲?def draw_landmarks_on_image(tools_dect, hand_dect, frame):\n",
    "    landmarks_list = hand_dect.hand_landmarks\n",
    "    annotated_image = np.copy(frame)\n",
    "\n",
    "    # ?꾧뎄 諛뺤뒪 洹몃━湲?    for (x1,y1,x2,y2), s, _ in tools_dect:\n",
    "        cv2.rectangle(annotated_image, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "\n",
    "    # ???쒕뱶留덊겕 洹몃━湲?    for landmark in landmarks_list:\n",
    "        landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "        for lm in landmark: \n",
    "            landmarks_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z)])\n",
    "            \n",
    "        solutions.drawing_utils.draw_landmarks(\n",
    "            annotated_image,\n",
    "            landmarks_proto,\n",
    "            solutions.hands.HAND_CONNECTIONS,\n",
    "            solutions.drawing_styles.get_default_hand_landmarks_style()\n",
    "        )\n",
    "\n",
    "    return annotated_image\n",
    "\n",
    "# 寃뱀묩 ?뺤씤\n",
    "# xyxy: x, y, ?덈퉬, ?믪씠\n",
    "# aknife : 0; blade: 1; handle: 2\n",
    "def detection_box(tools_dect, hand_dect, frame):\n",
    "    annotated_image = np.copy(frame)\n",
    "        \n",
    "    # boolean 留덉뒪??    # ?좉낵 ?먯옟?댁씤 寃쎌슦留?媛?몄샂\n",
    "    blade_xy = [ tools[0] for tools in tools_dect if tools[2] == 0 ]\n",
    "    handle_xy = [ tools[0] for tools in tools_dect if tools[2] == 1 ]\n",
    "    \n",
    "    # ?댁쟾 ?꾨젅??醫뚰몴 ???    global handle_pixel, blade_pixel\n",
    "    if len(handle_xy) > 0:\n",
    "        handle_pixel = save_pixel(handle_xy)\n",
    "        \n",
    "    if len(blade_xy) > 0:\n",
    "        blade_pixel = save_pixel(blade_xy)\n",
    "\n",
    "    # ?먯씠 寃뱀낀?붿? ?뺤씤\n",
    "    hand_list = hand_dect.hand_landmarks\n",
    "    H, W, _ = annotated_image.shape\n",
    "    \n",
    "    flag_blade = False; flag_handle = False\n",
    "    flag_Up = False; flag_Down = False; flag_Left = False; flag_Right = False\n",
    "    for hand in hand_list:\n",
    "        middle_x = int(hand[9].x * W)\n",
    "        middle_y = int(hand[9].y * H)\n",
    "        cv2.circle(annotated_image, (middle_x, middle_y), 5, (255,255,0), -1, cv2.LINE_AA)\n",
    "        \n",
    "        # ?먯옟???뺤씤\n",
    "        for handle in handle_pixel:\n",
    "            handle_middle_x = (handle[0] + handle[2]) // 2\n",
    "            handle_middle_y = (handle[1] + handle[3]) // 2\n",
    "            cv2.circle(annotated_image, (handle_middle_x, handle_middle_y), 3, (255,255,0), -1, cv2.LINE_AA)\n",
    "\n",
    "            if check_inside(handle, middle_x, middle_y):\n",
    "                flag_handle = True\n",
    "                break\n",
    "\n",
    "            # show_derection\n",
    "            if middle_x < handle_middle_x-DETECT_PADDING: flag_Right = True\n",
    "            elif middle_x > handle_middle_x+DETECT_PADDING: flag_Left = True\n",
    "                    \n",
    "            if middle_y < handle_middle_y-DETECT_PADDING: flag_Down = True\n",
    "            elif middle_y > handle_middle_y+DETECT_PADDING: flag_Up = True\n",
    "            \n",
    "        \n",
    "        for lm in hand:\n",
    "            lm_x = int(lm.x * W)\n",
    "            lm_y = int(lm.y * H)\n",
    "            \n",
    "            # ???뺤씤\n",
    "            for blade in blade_pixel:\n",
    "                if check_inside(blade, lm_x, lm_y):\n",
    "                    flag_blade = True\n",
    "                    break\n",
    "\n",
    "    \n",
    "                    \n",
    "    # 10: Right; 22: Left; 17: Up; 27: Down\n",
    "    # 16: Left-Up; 21: Right-Up; 20: Right-Down; 12:Left-Down\n",
    "    # 5: center\n",
    "    false_LED()\n",
    "    if flag_Left:\n",
    "        if flag_Up: GPIO.output(16, True)\n",
    "        elif flag_Down: GPIO.output(21, True)\n",
    "        else: GPIO.output(10, True)\n",
    "    elif flag_Right:\n",
    "        if flag_Up: GPIO.output(12, True)\n",
    "        elif flag_Down: GPIO.output(16, True)\n",
    "        else: GPIO.output(22, True)\n",
    "    else:\n",
    "        if flag_Up: GPIO.output(27, True)\n",
    "        elif flag_Down: GPIO.output(17, True)\n",
    "\n",
    "    if flag_blade:\n",
    "        if flag_handle:\n",
    "            detected_LED()\n",
    "        else:\n",
    "            GPIO.output(9, True)\n",
    "    elif flag_handle:\n",
    "        detected_LED()\n",
    "                                \n",
    "    return annotated_image\n",
    "\n",
    "def save_pixel(boxes):\n",
    "    lr = []\n",
    "    for x1,y1,x2,y2 in boxes:\n",
    "        lr.append([x1,y1,x2,y2])\n",
    "    return lr\n",
    "\n",
    "def check_inside(box, x, y):\n",
    "    if box[0] <= x <= box[2] and box[1] <= y <= box[3]: \n",
    "        return True\n",
    "    else: return False\n",
    "\n",
    "def false_LED():\n",
    "    GPIO.output(10,False); GPIO.output(22,False)\n",
    "    GPIO.output(17,False); GPIO.output(27,False)\n",
    "\n",
    "    GPIO.output(21,False); GPIO.output(20,False)\n",
    "    GPIO.output(16,False); GPIO.output(12,False)\n",
    "    GPIO.output(9,False)\n",
    "\n",
    "def detected_LED():\n",
    "    GPIO.output(10,True); GPIO.output(22,True)\n",
    "    GPIO.output(17,True); GPIO.output(27,True)\n",
    "\n",
    "    GPIO.output(21,True); GPIO.output(20,True)\n",
    "    GPIO.output(16,True); GPIO.output(12,True)\n",
    "\n",
    "# ?꾩쿂由?def letterbox(img, new=IMG_SIZE, color=(114,114,114)):\n",
    "    h, w = img.shape[:2]\n",
    "    r = min(new / h, new / w)\n",
    "    nh, nw = int(round(h * r)), int(round(w * r))\n",
    "    resized = cv2.resize(img, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "    canvas = np.full((new, new, 3), color, dtype=np.uint8)\n",
    "    top = (new - nh) // 2\n",
    "    left = (new - nw) // 2\n",
    "    canvas[top:top+nh, left:left+nw] = resized\n",
    "    return canvas, r, left, top\n",
    "\n",
    "def nms(dets, iou_th=IOU_TH):\n",
    "    # dets: [([x1,y1,x2,y2], score, cls_id), ...] in letterbox 醫뚰몴\n",
    "    if not dets: return []\n",
    "    boxes = np.array([d[0] for d in dets], dtype=np.float32)\n",
    "    scores = np.array([d[1] for d in dets], dtype=np.float32)\n",
    "    order = scores.argsort()[::-1]\n",
    "    keep = []\n",
    "    while order.size > 0:\n",
    "        i = order[0]\n",
    "        keep.append(i)\n",
    "        if order.size == 1: break\n",
    "        rest = order[1:]\n",
    "        xx1 = np.maximum(boxes[i,0], boxes[rest,0])\n",
    "        yy1 = np.maximum(boxes[i,1], boxes[rest,1])\n",
    "        xx2 = np.minimum(boxes[i,2], boxes[rest,2])\n",
    "        yy2 = np.minimum(boxes[i,3], boxes[rest,3])\n",
    "        inter = np.maximum(0.0, xx2 - xx1) * np.maximum(0.0, yy2 - yy1)\n",
    "        area_i = (boxes[i,2] - boxes[i,0]) * (boxes[i,3] - boxes[i,1])\n",
    "        area_r = (boxes[rest,2] - boxes[rest,0]) * (boxes[rest,3] - boxes[rest,1])\n",
    "        iou = inter / (area_i + area_r - inter + 1e-6)\n",
    "        order = rest[iou <= iou_th]\n",
    "    return [dets[k] for k in keep]\n",
    "\n",
    "def tools_inference(frame):\n",
    "    H, W, _ = frame.shape\n",
    "    img_lbx, r, lpad, tpad = letterbox(frame, IMG_SIZE)\n",
    "    img_rgb = cv2.cvtColor(img_lbx, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    input_mat = ncnn.Mat.from_pixels(img_rgb, ncnn.Mat.PixelType.PIXEL_RGB, IMG_SIZE, IMG_SIZE)\n",
    "    input_mat.substract_mean_normalize([0,0,0], [1/255.0, 1/255.0, 1/255.0])\n",
    "\n",
    "    # 異붾줎 ?쒖옉\n",
    "    ex = net.create_extractor()\n",
    "    ex.input(\"in0\", input_mat)\n",
    "    _, result = ex.extract(\"out0\")\n",
    "\n",
    "    arr = result.numpy()\n",
    "    D, N = arr.shape\n",
    "    A = arr.T  # (N, D) : ???됱씠 ???꾨낫\n",
    "    cx, cy, w, h = A[:, 0], A[:, 1], A[:, 2], A[:, 3]\n",
    "\n",
    "    cls_scores = A[:, 4:7]              # (N,3)\n",
    "    cls_ids = np.argmax(cls_scores, axis=1)\n",
    "    scores  = cls_scores[np.arange(N), cls_ids]\n",
    "    \n",
    "    # ?몄떇瑜좊줈 媛?몄삤湲?    keep = scores >= CONF_TH\n",
    "    if not np.any(keep): return []\n",
    "    cx = cx[keep]; cy = cy[keep]; w = w[keep]; h = h[keep]\n",
    "    scores = scores[keep]; cls_ids = cls_ids[keep]\n",
    "\n",
    "    # cxcywh -> xyxy (?덊꽣諛뺤뒪??IMG_SIZE 湲곗?)\n",
    "    x1 = cx - w/2; y1 = cy - h/2\n",
    "    x2 = cx + w/2; y2 = cy + h/2\n",
    "\n",
    "    # ?먮낯 醫뚰몴濡??????    x1 = (x1 - lpad) / r; y1 = (y1 - tpad) / r\n",
    "    x2 = (x2 - lpad) / r; y2 = (y2 - tpad) / r\n",
    "\n",
    "    # ?대━??    x1 = np.clip(x1, 0, W); y1 = np.clip(y1, 0, H)\n",
    "    x2 = np.clip(x2, 0, W); y2 = np.clip(y2, 0, H)\n",
    "\n",
    "    dets = [(\n",
    "        [int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])], \n",
    "        float(scores[i]), int(cls_ids[i])\n",
    "        ) \n",
    "        for i in range(len(scores))\n",
    "    ]\n",
    "\n",
    "    dets = nms(dets, IOU_TH)\n",
    "\n",
    "    return dets\n",
    "# ===================================================\n",
    "# ???쒕뱶留덊겕 紐⑤뜽 媛?몄삤湲?base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=1)\n",
    "hand_detector = vision.HandLandmarker.create_from_options(options)\n",
    "# ===================================================\n",
    "# 移?援щ텇 紐⑤뜽 媛?몄삤湲?(ncnn ?ㅽ듃)\n",
    "net = ncnn.Net()\n",
    "net.opt.num_threads = 4\n",
    "net.opt.use_fp16_storage = True\n",
    "net.opt.use_fp16_arithmetic = True\n",
    "\n",
    "net.load_param(\"knife_total_320.ncnn.param\")\n",
    "net.load_model(\"knife_total_320.ncnn.bin\")\n",
    "# ===================================================\n",
    "\n",
    "# 罹??닿린\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"??罹좎쓣 ?????놁뒿?덈떎\")\n",
    "    exit()\n",
    "\n",
    "fid = 0\n",
    "GPIO.setmode(GPIO.BCM)\n",
    "GPIO.setup(10,GPIO.OUT); GPIO.setup(22,GPIO.OUT); GPIO.setup(17,GPIO.OUT); GPIO.setup(27,GPIO.OUT)\n",
    "GPIO.setup(21,GPIO.OUT); GPIO.setup(20,GPIO.OUT); GPIO.setup(16,GPIO.OUT); GPIO.setup(12,GPIO.OUT)\n",
    "GPIO.setup(9,GPIO.OUT)\n",
    "\n",
    "# ?ㅽ뻾遺\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame_bgr = cv2.cvtColor(frame,cv2.COLOR_BGR2RGB)\n",
    "    mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_bgr)\n",
    "\n",
    "    # ?꾨젅???ㅽ궢\n",
    "    fid += 1\n",
    "    if fid % (FRAME_SKIP + 1) == 1:\n",
    "        tools_result = tools_inference(frame)\n",
    "        hand_result = hand_detector.detect(mp_image)\n",
    "\n",
    "    # 寃곌낵 洹몃━湲?    drawing_image = draw_landmarks_on_image(tools_result, hand_result, frame)\n",
    "    annotated_image = detection_box(tools_result, hand_result, drawing_image)\n",
    "\n",
    "    cv2.imshow(\"hand_land\", annotated_image)\n",
    "\n",
    "    # q?ㅻ? ?꾨Ⅴ硫?醫낅즺\n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        false_LED()\n",
    "        break\n",
    "    \n",
    "# 醫낅즺 ???먯썝 ?댁젣\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
