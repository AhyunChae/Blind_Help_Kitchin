{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b72dfbbb-e097-4475-afa5-23eb399c9834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, torch, pandas, numpy as np, threading, queue, ncnn, sounddevice as sd, scipy.io.wavfile\n",
    "\n",
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "\n",
    "IMG_SIZE = 320\n",
    "CONF_TH = 0.7\n",
    "FRAME_SKIP = 2\n",
    "IOU_TH = 0.25\n",
    "\n",
    "WARNING_TXT_ORG = (30,30)\n",
    "DERECTION_ORG = (430,450)\n",
    "\n",
    "COLOR_RED = (0,0,255)\n",
    "COLOR_GREEN = (0,255,0)\n",
    "COLOR_BLUE = (255,0,0)\n",
    "\n",
    "HANDLE_PIXEL = []\n",
    "BLADE_PIXEL = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dda7ede1-7ceb-47a7-8ec8-6f9785659a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CV2_CAM:\n",
    "    def __init__(self, frame):\n",
    "        self.annotated_image = np.copy(frame)\n",
    "        self.H, self.W, self.C = frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bc80ac1e-a3e9-44c2-a450-ca1653d94690",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(CV2_CAM):\n",
    "    def __init__(self, frame):\n",
    "        super().__init__(frame)\n",
    "        frame_bgr = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_bgr)\n",
    "            \n",
    "        self.hand_result = hand_detector.detect(mp_image).hand_landmarks\n",
    "        self.tools_result = self.tools_inference()\n",
    "\n",
    "    def get_result(self):\n",
    "        return self.tools_result, self.hand_result\n",
    "\n",
    "    def tools_inference(self):\n",
    "        img_lbx, r, lpad, tpad = self.letterbox(IMG_SIZE)\n",
    "        img_rgb = cv2.cvtColor(img_lbx, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        input_mat = ncnn.Mat.from_pixels(img_rgb, ncnn.Mat.PixelType.PIXEL_RGB, IMG_SIZE, IMG_SIZE)\n",
    "        input_mat.substract_mean_normalize([0,0,0], [1/255.0, 1/255.0, 1/255.0])\n",
    "    \n",
    "        # 추론 시작\n",
    "        ex = net.create_extractor()\n",
    "        ex.input(\"in0\", input_mat)\n",
    "        _, result = ex.extract(\"out0\")\n",
    "    \n",
    "        arr = result.numpy()\n",
    "        D, N = arr.shape\n",
    "        A = arr.T  # (N, D) : 한 행이 한 후보\n",
    "        cx, cy, w, h = A[:, 0], A[:, 1], A[:, 2], A[:, 3]\n",
    "    \n",
    "        cls_scores = A[:, 4:7]              # (N,3)\n",
    "        cls_ids = np.argmax(cls_scores, axis=1)\n",
    "        scores  = cls_scores[np.arange(N), cls_ids]\n",
    "        \n",
    "        # 인식률로 가져오기\n",
    "        keep = scores >= CONF_TH\n",
    "        if not np.any(keep): return []\n",
    "        cx = cx[keep]; cy = cy[keep]; w = w[keep]; h = h[keep]\n",
    "        scores = scores[keep]; cls_ids = cls_ids[keep]\n",
    "    \n",
    "        # cxcywh -> xyxy (레터박스된 IMG_SIZE 기준)\n",
    "        x1 = cx - w/2; y1 = cy - h/2\n",
    "        x2 = cx + w/2; y2 = cy + h/2\n",
    "    \n",
    "        # 원본 좌표로 역변환\n",
    "        x1 = (x1 - lpad) / r; y1 = (y1 - tpad) / r\n",
    "        x2 = (x2 - lpad) / r; y2 = (y2 - tpad) / r\n",
    "    \n",
    "        # 클리핑\n",
    "        x1 = np.clip(x1, 0, self.W); y1 = np.clip(y1, 0, self.H)\n",
    "        x2 = np.clip(x2, 0, self.W); y2 = np.clip(y2, 0, self.H)\n",
    "    \n",
    "        dets = [(\n",
    "            [int(x1[i]), int(y1[i]), int(x2[i]), int(y2[i])], \n",
    "            float(scores[i]), int(cls_ids[i])\n",
    "            ) \n",
    "            for i in range(len(scores))\n",
    "        ]\n",
    "        dets = self.nms(dets, IOU_TH)\n",
    "        \n",
    "        return dets\n",
    "\n",
    "    # 전처리\n",
    "    def letterbox(self, new, color=(114,114,114)):\n",
    "        r = min(new / self.H, new / self.W)\n",
    "        nh, nw = int(round(self.H * r)), int(round(self.W * r))\n",
    "        resized = cv2.resize(self.annotated_image, (nw, nh), interpolation=cv2.INTER_AREA)\n",
    "        canvas = np.full((new, new, 3), color, dtype=np.uint8)\n",
    "        top = (new - nh) // 2\n",
    "        left = (new - nw) // 2\n",
    "        canvas[top:top+nh, left:left+nw] = resized\n",
    "        return canvas, r, left, top\n",
    "\n",
    "    def nms(self, dets, iou_th):\n",
    "        # dets: [([x1,y1,x2,y2], score, cls_id), ...] in letterbox 좌표\n",
    "        if not dets: return []\n",
    "        boxes = np.array([d[0] for d in dets], dtype=np.float32)\n",
    "        scores = np.array([d[1] for d in dets], dtype=np.float32)\n",
    "        order = scores.argsort()[::-1]\n",
    "        keep = []\n",
    "        while order.size > 0:\n",
    "            i = order[0]\n",
    "            keep.append(i)\n",
    "            if order.size == 1: break\n",
    "            rest = order[1:]\n",
    "            xx1 = np.maximum(boxes[i,0], boxes[rest,0])\n",
    "            yy1 = np.maximum(boxes[i,1], boxes[rest,1])\n",
    "            xx2 = np.minimum(boxes[i,2], boxes[rest,2])\n",
    "            yy2 = np.minimum(boxes[i,3], boxes[rest,3])\n",
    "            inter = np.maximum(0.0, xx2 - xx1) * np.maximum(0.0, yy2 - yy1)\n",
    "            area_i = (boxes[i,2] - boxes[i,0]) * (boxes[i,3] - boxes[i,1])\n",
    "            area_r = (boxes[rest,2] - boxes[rest,0]) * (boxes[rest,3] - boxes[rest,1])\n",
    "            iou = inter / (area_i + area_r - inter + 1e-6)\n",
    "            order = rest[iou <= iou_th]\n",
    "        return [dets[k] for k in keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20cb9962-cf58-483a-912c-bed606d1a21b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Draw(CV2_CAM):\n",
    "    def __init__(self, frame, tools_result, hand_result):\n",
    "        super().__init__(frame)\n",
    "        self.tools_result = tools_result\n",
    "        self.hand_result = hand_result\n",
    "\n",
    "    def draw_on_cv(self):\n",
    "        # 도구 박스 그리기\n",
    "        for (x1,y1,x2,y2), _, _ in self.tools_result:\n",
    "            cv2.rectangle(self.annotated_image, (x1,y1), (x2,y2), (0,0,255), 2)\n",
    "\n",
    "        # 손 랜드마크 그리기\n",
    "        for landmark in self.hand_result:\n",
    "            landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "            for lm in landmark: \n",
    "                landmarks_proto.landmark.extend([landmark_pb2.NormalizedLandmark(x=lm.x, y=lm.y, z=lm.z)])\n",
    "                \n",
    "            solutions.drawing_utils.draw_landmarks(\n",
    "                self.annotated_image,\n",
    "                landmarks_proto,\n",
    "                solutions.hands.HAND_CONNECTIONS,\n",
    "                solutions.drawing_styles.get_default_hand_landmarks_style()\n",
    "            )\n",
    "    \n",
    "        return self.annotated_image\n",
    "\n",
    "    def draw_circle(self, center, color):\n",
    "        cv2.circle(self.annotated_image, center, 5, color, -1, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d8b231f7-3ea9-494b-964f-3c518e507bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CheckBox(CV2_CAM):\n",
    "    def __init__(self, frame, tools_result, hand_result):\n",
    "        super().__init__(frame)\n",
    "        self.flag = self.flag_init()\n",
    "        self.hand_result = hand_result\n",
    "\n",
    "        blade_xy = [ tools[0] for tools in tools_result if tools[2] == 0 ]\n",
    "        handle_xy = [ tools[0] for tools in tools_result if tools[2] == 1 ]\n",
    "\n",
    "        global HANDLE_PIXEL, BLADE_PIXEL\n",
    "        if len(handle_xy) > 0:\n",
    "            HANDLE_PIXEL = self.save_pixel(handle_xy)\n",
    "        \n",
    "        if len(blade_xy) > 0:\n",
    "            BLADE_PIXEL = self.save_pixel(blade_xy)\n",
    "\n",
    "    def flag_init(self):\n",
    "        obj = {\n",
    "            \"handle\": False,\n",
    "            \"blade\": False\n",
    "        }\n",
    "\n",
    "        return obj\n",
    "\n",
    "    def save_pixel(self, boxes):\n",
    "        lr = []\n",
    "        for x1,y1,x2,y2 in boxes:\n",
    "            lr.append([x1,y1,x2,y2])\n",
    "        return lr\n",
    "    # ===========================================================\n",
    "    def detect_box(self):\n",
    "        for hand in self.hand_result:\n",
    "            self.check_handle(hand)\n",
    "\n",
    "            for lm in hand:\n",
    "                self.check_blade(lm)\n",
    "\n",
    "        self.check_flag()\n",
    "        return self.annotated_image\n",
    "    \n",
    "    def check_handle(self, hand):\n",
    "        middle_x = int(hand[9].x * self.W)\n",
    "        middle_y = int(hand[9].y * self.H)\n",
    "        cv2.circle(self.annotated_image, (middle_x, middle_y), 5, COLOR_BLUE, -1, cv2.LINE_AA)\n",
    "        \n",
    "        for handle in HANDLE_PIXEL:\n",
    "            handle_middle_x = (handle[0] + handle[2]) // 2\n",
    "            handle_middle_y = (handle[1] + handle[3]) // 2 \n",
    "            cv2.circle(self.annotated_image, (handle_middle_x, handle_middle_y), 5, (255,255,0), -1, cv2.LINE_AA)\n",
    "\n",
    "            if self.check_inside(handle, middle_x, middle_y):\n",
    "                self.flag[\"handle\"] = True\n",
    "                break\n",
    "                \n",
    "            if middle_x < handle_middle_x:\n",
    "                if middle_y < handle_middle_y:\n",
    "                    self.draw_text(\"Right-Up\", DERECTION_ORG, COLOR_BLUE)\n",
    "                else:\n",
    "                    self.draw_text(\"Right-Down\", DERECTION_ORG, COLOR_BLUE)\n",
    "                    \n",
    "            elif middle_x > handle_middle_x:\n",
    "                if middle_y < handle_middle_y:\n",
    "                    self.draw_text(\"Left-Up\", DERECTION_ORG, COLOR_BLUE)\n",
    "                else:\n",
    "                    self.draw_text(\"Left-Down\", DERECTION_ORG, COLOR_BLUE)\n",
    "                    \n",
    "    def check_blade(self, lm):\n",
    "        lm_x = int(lm.x * self.W)\n",
    "        lm_y = int(lm.y * self.H)\n",
    "        \n",
    "        # 날 확인\n",
    "        for blade in BLADE_PIXEL:\n",
    "            if self.check_inside(blade, lm_x, lm_y):\n",
    "                self.flag[\"blade\"] = True\n",
    "                break\n",
    "                \n",
    "    def check_flag(self):\n",
    "        if self.flag[\"blade\"]:\n",
    "            if self.flag[\"handle\"]:\n",
    "                self.draw_text(\"DETECTED\", WARNING_TXT_ORG, COLOR_GREEN)\n",
    "            else:\n",
    "                self.draw_text(\"DANGER\", WARNING_TXT_ORG, COLOR_RED)\n",
    "        elif self.flag[\"handle\"]:\n",
    "            self.draw_text(\"DETECTED\", WARNING_TXT_ORG, COLOR_GREEN)\n",
    "    # ===========================================================\n",
    "    def check_inside(self, box, x, y):\n",
    "        if box[0] <= x <= box[2] and box[1] <= y <= box[3]: \n",
    "            return True\n",
    "        else: return False\n",
    "            \n",
    "    def draw_text(self, text, org, color):\n",
    "        cv2.putText(self.annotated_image, text, org, cv2.FONT_HERSHEY_SIMPLEX, 1, color, 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "88f2bf1c-2124-43e5-8a1b-a138e8d2d09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_cv2(cap):\n",
    "    global FID\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret: break\n",
    "\n",
    "        # 프레임 스킵\n",
    "        FID += 1\n",
    "        if FID % (FRAME_SKIP + 1) == 1:\n",
    "            tools_result, hand_result = Detector(frame).get_result()\n",
    "\n",
    "        # result 그리기\n",
    "        drawing_image = Draw(frame, tools_result, hand_result).draw_on_cv()\n",
    "        # 감지 확인\n",
    "        annotated_image = CheckBox(drawing_image, tools_result, hand_result).detect_box()\n",
    "        \n",
    "        cv2.imshow(\"hand_land\", annotated_image)\n",
    "\n",
    "        # q키를 누르면 종료\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "# 손 랜드마크 모델 가져오기\n",
    "base_options = python.BaseOptions(model_asset_path='hand_landmarker.task')\n",
    "options = vision.HandLandmarkerOptions(base_options=base_options, num_hands=2)\n",
    "hand_detector = vision.HandLandmarker.create_from_options(options)\n",
    "# ===================================================\n",
    "# 칼 구분 모델 가져오기 (ncnn 네트)\n",
    "net = ncnn.Net()\n",
    "net.opt.num_threads = 4\n",
    "net.opt.use_fp16_storage = True\n",
    "net.opt.use_fp16_arithmetic = True\n",
    "\n",
    "net.load_param(\"knife_total_320.ncnn.param\")\n",
    "net.load_model(\"knife_total_320.ncnn.bin\")\n",
    "# ===================================================\n",
    "# 캠 열기\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"웹 캠을 열 수 없습니다\")\n",
    "    exit()\n",
    "FID = 0\n",
    "show_cv2(cap)\n",
    "\n",
    "# 종료 시 자원 해제\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1e64d9-7b4c-4899-a97b-7538ae8f7030",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
